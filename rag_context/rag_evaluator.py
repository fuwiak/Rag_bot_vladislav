"""
RAG Quality Evaluator - Golden Standard Implementation
Evaluates RAG system using Ground-Truth QA pairs with metrics:
- Precision@K (‚â•0.85 for regulated, ‚â•0.75 for general)
- Halucination Rate (fact-checking against sources)
- MRR (Mean Reciprocal Rank, target ‚â•0.9)
- Groundedness (target ‚â•0.9)
"""

import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
import asyncio
from rag_chain import RAGChain
from qdrant_loader import QdrantLoader

logger = logging.getLogger(__name__)


@dataclass
class GroundTruthQA:
    """Ground-Truth QA –ø–∞—Ä–∞"""
    question: str
    expected_answer: str
    category: str  # "regulated" –∏–ª–∏ "general"
    expected_sources: List[str]  # –û–∂–∏–¥–∞–µ–º—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    key_facts: List[str]  # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏


@dataclass
class EvaluationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ –æ–¥–Ω–æ–≥–æ QA"""
    question: str
    expected_answer: str
    actual_answer: str
    category: str
    precision_at_k: float
    mrr: float
    groundedness: float
    halucination_rate: float
    retrieved_sources: List[str]
    expected_sources: List[str]
    matched_sources: List[str]
    error: Optional[str] = None


@dataclass
class EvaluationSummary:
    """–°–≤–æ–¥–∫–∞ –æ—Ü–µ–Ω–∫–∏"""
    total_questions: int
    precision_at_k_regulated: float
    precision_at_k_general: float
    precision_at_k_overall: float
    mrr_overall: float
    groundedness_overall: float
    halucination_rate_overall: float
    timestamp: str
    results: List[EvaluationResult]


class HalucinationDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤ –ø—Ä–æ—Ç–∏–≤ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__ + ".HalucinationDetector")
    
    def check_facts(
        self,
        answer: str,
        context_docs: List[Dict[str, Any]],
        key_facts: Optional[List[str]] = None
    ) -> Tuple[float, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–∫—Ç—ã –≤ –æ—Ç–≤–µ—Ç–µ –ø—Ä–æ—Ç–∏–≤ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
        
        Args:
            answer: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
            context_docs: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ RAG
            key_facts: –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            Tuple[groundedness_score, halucinated_facts]
            - groundedness_score: 0.0-1.0 (1.0 = –≤—Å–µ —Ñ–∞–∫—Ç—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã)
            - halucinated_facts: —Å–ø–∏—Å–æ–∫ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        """
        if not context_docs:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –Ω–æ –µ—Å—Ç—å key_facts - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö –≤ –æ—Ç–≤–µ—Ç–µ
            # –≠—Ç–æ –∑–Ω–∞—á–∏—Ç LLM –º–æ–≥ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
            # –≠—Ç–æ —á–∞—Å—Ç–∏—á–Ω–æ –≤–∞–ª–∏–¥–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è - –Ω–µ –ø–æ–ª–Ω–∞—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
            if key_facts and answer:
                answer_lower = answer.lower()
                matched_facts = sum(1 for fact in key_facts if fact.lower() in answer_lower)
                if matched_facts > 0:
                    # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–∫—Ç—ã –µ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ - —á–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
                    # –ù–æ –≤—Å–µ —Ä–∞–≤–Ω–æ —Å–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    groundedness = min(0.4, matched_facts / len(key_facts) * 0.6)  # –ú–∞–∫—Å–∏–º—É–º 0.4 –¥–∞–∂–µ –ø—Ä–∏ –≤—Å–µ—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è—Ö
                    return groundedness, []
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π - –≤—Å–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
            # –ù–æ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç –∫–∞–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—é - —ç—Ç–æ —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–æ
            if answer:
                return 0.0, ["–ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤"]
            return 0.0, []
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
        context_text = " ".join([doc.get("text", "") for doc in context_docs])
        context_text_lower = context_text.lower()
        answer_lower = answer.lower()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø—Ä–æ—Å—Ç—ã–µ —Ñ–∞–∫—Ç—ã)
        sentences = self._extract_facts(answer)
        
        if not sentences:
            return 1.0, []  # –ù–µ—Ç —Ñ–∞–∫—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
        grounded_count = 0
        halucinated = []
        
        for fact in sentences:
            if self._fact_grounded(fact, context_text_lower, key_facts):
                grounded_count += 1
            else:
                halucinated.append(fact[:100])
        
        groundedness = grounded_count / len(sentences) if sentences else 1.0
        halucination_rate = 1.0 - groundedness
        
        return groundedness, halucinated[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –ø—Ä–∏–º–µ—Ä–æ–≤
    
    def _extract_facts(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"""
        if not text or len(text.strip()) < 10:
            return []
        
        import re
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]\s+', text)
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        facts = [
            s.strip() for s in sentences
            if len(s.strip()) > 12 and not s.strip().startswith(('–ò—Å—Ç–æ—á–Ω–∏–∫–∏:', 'üìö', '–ï—Å–ª–∏', '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞', '–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é', '–û–¥–Ω–∞–∫–æ', '–í–æ–ø—Ä–æ—Å', '–û—Ç–≤–µ—Ç'))
        ]
        
        # –ï—Å–ª–∏ —Ñ–∞–∫—Ç–æ–≤ –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º
        if len(facts) < 2 and ',' in text:
            comma_split = text.split(',')
            facts.extend([
                s.strip() for s in comma_split
                if len(s.strip()) > 15 and not s.strip().startswith(('–ò—Å—Ç–æ—á–Ω–∏–∫–∏:', 'üìö'))
            ])
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç—ã
        facts = list(dict.fromkeys(facts))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        facts = [f for f in facts if len(f) > 12]  # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
        
        return facts[:10]  # –ú–∞–∫—Å–∏–º—É–º 10 —Ñ–∞–∫—Ç–æ–≤
    
    def _fact_grounded(
        self,
        fact: str,
        context: str,
        key_facts: Optional[List[str]] = None
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω –ª–∏ —Ñ–∞–∫—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        fact_lower = fact.lower()
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å
        if key_facts:
            for key_fact in key_facts:
                if key_fact.lower() in fact_lower and key_fact.lower() in context:
                    return True
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ñ–∞–∫—Ç–∞
        import re
        words = re.findall(r'\b\w{4,}\b', fact_lower)  # –°–ª–æ–≤–∞ –¥–ª–∏–Ω–æ–π >= 4 —Å–∏–º–≤–æ–ª–æ–≤
        
        if not words:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        # –ù—É–∂–Ω–æ —á—Ç–æ–±—ã —Ö–æ—Ç—è –±—ã 50% –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±—ã–ª–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        matched_words = sum(1 for word in words if word in context)
        match_ratio = matched_words / len(words) if words else 0
        
        # –ï—Å–ª–∏ >50% —Å–ª–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç - —Å—á–∏—Ç–∞–µ–º —Ñ–∞–∫—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–º
        return match_ratio >= 0.5


class RAGEvaluator:
    """–û—Ü–µ–Ω—â–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, rag_chain: Optional[RAGChain] = None):
        self.rag_chain = rag_chain or RAGChain()
        self.halucination_detector = HalucinationDetector()
        self.logger = logging.getLogger(__name__ + ".RAGEvaluator")
    
    async def evaluate(
        self,
        ground_truth_qa: List[GroundTruthQA],
        k: int = 5
    ) -> EvaluationSummary:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç RAG —Å–∏—Å—Ç–µ–º—É –Ω–∞ Ground-Truth QA –Ω–∞–±–æ—Ä–µ.
        
        Args:
            ground_truth_qa: –°–ø–∏—Å–æ–∫ Ground-Truth QA –ø–∞—Ä
            k: K –¥–ª—è Precision@K
        
        Returns:
            EvaluationSummary —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        self.logger.info(f"–ù–∞—á–∏–Ω–∞—é –æ—Ü–µ–Ω–∫—É –Ω–∞ {len(ground_truth_qa)} QA –ø–∞—Ä–∞—Ö...")
        
        results = []
        
        for i, qa in enumerate(ground_truth_qa, 1):
            self.logger.info(f"–û—Ü–µ–Ω–∫–∞ {i}/{len(ground_truth_qa)}: {qa.question[:60]}...")
            
            try:
                result = await self._evaluate_single(qa, k)
                results.append(result)
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ QA {i}: {str(e)}")
                results.append(EvaluationResult(
                    question=qa.question,
                    expected_answer=qa.expected_answer,
                    actual_answer="",
                    category=qa.category,
                    precision_at_k=0.0,
                    mrr=0.0,
                    groundedness=0.0,
                    halucination_rate=1.0,
                    retrieved_sources=[],
                    expected_sources=qa.expected_sources,
                    matched_sources=[],
                    error=str(e)
                ))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        summary = self._calculate_summary(results)
        
        return summary
    
    async def _evaluate_single(
        self,
        qa: GroundTruthQA,
        k: int
    ) -> EvaluationResult:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ–¥–∏–Ω QA"""
        # –í—ã–ø–æ–ª–Ω—è–µ–º RAG –∑–∞–ø—Ä–æ—Å
        rag_result = await self.rag_chain.query(
            user_query=qa.question,
            use_rag=True,
            top_k=k
        )
        
        actual_answer = rag_result.get("answer", "")
        context_count = rag_result.get("context_count", 0)
        retrieved_sources = rag_result.get("sources", [])
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á—Ç–æ –∏ –≤ RAG –∑–∞–ø—Ä–æ—Å–µ
        context_docs = await self._get_context_docs(qa.question, k)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        if not context_docs:
            self.logger.warning(
                f"‚ö†Ô∏è –ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤ –≤ –≤–æ–ø—Ä–æ—Å–µ: {qa.question[:60]}..."
            )
            self.logger.warning(
                f"   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã: Qdrant –ø—É—Å—Ç, –ø–æ—Ä–æ–≥–∏ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–µ, "
                f"–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"
            )
        
        # Precision@K - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        precision_at_k = self._calculate_precision_at_k(
            retrieved_sources,
            qa.expected_sources,
            k
        )
        
        # MRR (Mean Reciprocal Rank)
        mrr = self._calculate_mrr(
            retrieved_sources,
            qa.expected_sources
        )
        
        # Groundedness –∏ Halucination Rate
        groundedness, halucinated = self.halucination_detector.check_facts(
            actual_answer,
            context_docs,
            qa.key_facts
        )
        halucination_rate = 1.0 - groundedness
        
        # –ú–∞—Ç—á–∏–Ω–≥ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        matched_sources = [
            src for src in retrieved_sources
            if any(exp in src or src in exp for exp in qa.expected_sources)
        ]
        
        return EvaluationResult(
            question=qa.question,
            expected_answer=qa.expected_answer,
            actual_answer=actual_answer,
            category=qa.category,
            precision_at_k=precision_at_k,
            mrr=mrr,
            groundedness=groundedness,
            halucination_rate=halucination_rate,
            retrieved_sources=retrieved_sources,
            expected_sources=qa.expected_sources,
            matched_sources=matched_sources
        )
    
    async def _get_context_docs(self, query: str, k: int) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Å —Ñ–∏–ª—å—Ç—Ä–æ–º whitelist
            docs = self.rag_chain.qdrant_loader.search(
                query=query,
                top_k=k * 2,  # –ë–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                score_threshold=0.2,  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
                filter_by_whitelist=True
            )
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
            if not docs:
                self.logger.debug(f"–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞...")
                docs = self.rag_chain.qdrant_loader.search(
                    query=query,
                    top_k=k * 2,
                    score_threshold=0.2,
                    filter_by_whitelist=False
                )
            
            return docs[:k]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)}")
            return []
    
    def _calculate_precision_at_k(
        self,
        retrieved: List[str],
        expected: List[str],
        k: int
    ) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç Precision@K.
        Precision@K = (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤ —Ç–æ–ø-K) / K
        """
        if not retrieved:
            return 0.0
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        retrieved_normalized = [self._normalize_url(url) for url in retrieved[:k]]
        expected_normalized = [self._normalize_url(url) for url in expected]
        
        # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
        relevant_count = sum(
            1 for url in retrieved_normalized
            if any(exp in url or url in exp for exp in expected_normalized)
        )
        
        precision = relevant_count / min(k, len(retrieved)) if retrieved else 0.0
        return precision
    
    def _calculate_mrr(
        self,
        retrieved: List[str],
        expected: List[str]
    ) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç MRR (Mean Reciprocal Rank).
        MRR = 1 / rank –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        if not retrieved or not expected:
            return 0.0
        
        retrieved_normalized = [self._normalize_url(url) for url in retrieved]
        expected_normalized = [self._normalize_url(url) for url in expected]
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ
        for rank, url in enumerate(retrieved_normalized, 1):
            if any(exp in url or url in exp for exp in expected_normalized):
                return 1.0 / rank
        
        return 0.0
    
    def _normalize_url(self, url: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç URL –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        url = url.lower().strip()
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª –∏ www
        url = url.replace("https://", "").replace("http://", "").replace("www.", "")
        # –£–±–∏—Ä–∞–µ–º trailing slash
        url = url.rstrip("/")
        return url
    
    def _calculate_summary(self, results: List[EvaluationResult]) -> EvaluationSummary:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        if not results:
            return EvaluationSummary(
                total_questions=0,
                precision_at_k_regulated=0.0,
                precision_at_k_general=0.0,
                precision_at_k_overall=0.0,
                mrr_overall=0.0,
                groundedness_overall=0.0,
                halucination_rate_overall=1.0,
                timestamp=datetime.now().isoformat(),
                results=[]
            )
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        regulated = [r for r in results if r.category == "regulated"]
        general = [r for r in results if r.category == "general"]
        
        # Precision@K
        precision_regulated = (
            sum(r.precision_at_k for r in regulated) / len(regulated)
            if regulated else 0.0
        )
        precision_general = (
            sum(r.precision_at_k for r in general) / len(general)
            if general else 0.0
        )
        precision_overall = sum(r.precision_at_k for r in results) / len(results)
        
        # MRR
        mrr_overall = sum(r.mrr for r in results) / len(results)
        
        # Groundedness
        groundedness_overall = sum(r.groundedness for r in results) / len(results)
        
        # Halucination Rate
        halucination_overall = sum(r.halucination_rate for r in results) / len(results)
        
        return EvaluationSummary(
            total_questions=len(results),
            precision_at_k_regulated=precision_regulated,
            precision_at_k_general=precision_general,
            precision_at_k_overall=precision_overall,
            mrr_overall=mrr_overall,
            groundedness_overall=groundedness_overall,
            halucination_rate_overall=halucination_overall,
            timestamp=datetime.now().isoformat(),
            results=results
        )
    
    def save_results(
        self,
        summary: EvaluationSummary,
        output_path: str = "evaluation_results.json"
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –≤ JSON"""
        output = {
            "summary": {
                "total_questions": summary.total_questions,
                "precision_at_k_regulated": summary.precision_at_k_regulated,
                "precision_at_k_general": summary.precision_at_k_general,
                "precision_at_k_overall": summary.precision_at_k_overall,
                "mrr_overall": summary.mrr_overall,
                "groundedness_overall": summary.groundedness_overall,
                "halucination_rate_overall": summary.halucination_rate_overall,
                "timestamp": summary.timestamp
            },
            "results": [asdict(r) for r in summary.results]
        }
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        await self.rag_chain.close()

