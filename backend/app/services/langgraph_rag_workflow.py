"""
LangGraph RAG Workflow –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ê–Ω–∞–ª–∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∏—Å–∫–∞–∂–µ–Ω–∏—è–º–∏
- –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- –û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
"""
import logging
from typing import List, Dict, Any, Optional, TypedDict, Annotated
from uuid import UUID
from enum import Enum
import operator
from dataclasses import dataclass

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å LangGraph
try:
    from langgraph.graph import StateGraph, END
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    logger.warning("LangGraph –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langgraph langchain-core")


class QueryType(str, Enum):
    """–¢–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è RAG"""
    QUESTION = "question"  # –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
    SUMMARY = "summary"  # –†–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞/–±–ª–æ–∫–∞
    DESCRIPTION = "description"  # –û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
    ANALYSIS = "analysis"  # –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞


@dataclass
class RAGConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è RAG workflow"""
    # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    
    # –î–ª—è GPT-4 / Claude: –º–∞–∫—Å. –∫–æ–Ω—Ç–µ–∫—Å—Ç ~128k —Ç–æ–∫–µ–Ω–æ–≤
    # –î–ª—è GPT-3.5: –º–∞–∫—Å. –∫–æ–Ω—Ç–µ–∫—Å—Ç ~16k —Ç–æ–∫–µ–Ω–æ–≤
    # –î–ª—è DeepSeek: –º–∞–∫—Å. –∫–æ–Ω—Ç–µ–∫—Å—Ç ~64k —Ç–æ–∫–µ–Ω–æ–≤
    
    max_context_tokens: int = 100000  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    max_output_tokens: int = 4096  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞
    chunk_size: int = 1500  # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (—Å–∏–º–≤–æ–ª–æ–≤)
    chunk_overlap: int = 300  # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —á–∞–Ω–∫–æ–≤
    top_k_retrieval: int = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    temperature: float = 0.2  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
    
    # –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
    system_prompts: Dict[QueryType, str] = None
    
    def __post_init__(self):
        if self.system_prompts is None:
            self.system_prompts = {
                QueryType.QUESTION: """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
                
–ü—Ä–∞–≤–∏–ª–∞:
1. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ - —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
2. –¶–∏—Ç–∏—Ä—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
3. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
4. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É
5. –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: —Ä—É—Å—Å–∫–∏–π""",
                
                QueryType.SUMMARY: """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ó–∞–¥–∞—á–∞: –°–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ, –Ω–æ –ø–æ–ª–Ω–æ–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –î–ª–∏–Ω–∞: 500-1000 —Å–∏–º–≤–æ–ª–æ–≤
2. –í–∫–ª—é—á–∏ –í–°–ï –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ —Ñ–∞–∫—Ç—ã
3. –°–æ—Ö—Ä–∞–Ω–∏ —Ç–æ—á–Ω–æ—Å—Ç—å: —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –∏–º–µ–Ω–∞, —Ç–µ—Ä–º–∏–Ω—ã
4. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –≥–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞ ‚Üí –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã ‚Üí –≤—ã–≤–æ–¥—ã
5. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è - –Ω–µ –¥–æ–±–∞–≤–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç
6. –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π""",
                
                QueryType.DESCRIPTION: """–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ–ø–∏—Å–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –û–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ —Ä–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
2. –£–∫–∞–∂–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ—Ç—á–µ—Ç, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –¥–æ–≥–æ–≤–æ—Ä –∏ —Ç.–¥.)
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–∫–æ–º–ø–∞–Ω–∏–∏, –ª—é–¥–∏, –¥–∞—Ç—ã, —Å—É–º–º—ã)
4. –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
5. –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π""",
                
                QueryType.ANALYSIS: """–¢—ã –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ó–∞–¥–∞—á–∞: –ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ –¥–∞–Ω–Ω—ã–µ
3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –ª–æ–≥–∏–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
4. –í—ã—è–≤–∏ –≤–∞–∂–Ω—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
5. –°–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
6. –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π"""
            }


class RAGState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ RAG workflow"""
    query: str
    query_type: QueryType
    project_id: str
    document_id: Optional[str]
    chunks: List[Dict[str, Any]]
    context: str
    answer: str
    sources: List[str]
    confidence: float
    error: Optional[str]
    metadata: Dict[str, Any]


class LangGraphRAGWorkflow:
    """LangGraph RAG Workflow –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(
        self,
        db: AsyncSession,
        config: Optional[RAGConfig] = None
    ):
        self.db = db
        self.config = config or RAGConfig()
        self._workflow = None
        
        if LANGGRAPH_AVAILABLE:
            self._build_workflow()
    
    def _build_workflow(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ LangGraph workflow"""
        workflow = StateGraph(RAGState)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–¥—ã
        workflow.add_node("retrieve", self._retrieve_node)
        workflow.add_node("build_context", self._build_context_node)
        workflow.add_node("generate", self._generate_node)
        workflow.add_node("format_output", self._format_output_node)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞—Ñ
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "build_context")
        workflow.add_edge("build_context", "generate")
        workflow.add_edge("generate", "format_output")
        workflow.add_edge("format_output", END)
        
        self._workflow = workflow.compile()
    
    async def _retrieve_node(self, state: RAGState) -> RAGState:
        """–ù–æ–¥–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤"""
        logger.info(f"[LangGraph RAG] Retrieving chunks for query: {state['query'][:50]}...")
        
        try:
            from app.services.embedding_service import EmbeddingService
            from app.vector_db.vector_store import VectorStore
            
            embedding_service = EmbeddingService()
            vector_store = VectorStore()
            
            # –°–æ–∑–¥–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await embedding_service.create_embedding(state['query'])
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
            collection_name = f"project_{state['project_id']}"
            
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤
            results = await vector_store.search_similar(
                collection_name=collection_name,
                query_vector=query_embedding,
                limit=self.config.top_k_retrieval * 2,  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                score_threshold=0.3  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã
            )
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ document_id –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if state.get('document_id'):
                results = [
                    r for r in results 
                    if r.get('payload', {}).get('document_id') == state['document_id']
                ]
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∞–Ω–∫–∏
            chunks = []
            for r in results[:self.config.top_k_retrieval]:
                payload = r.get('payload', {})
                chunk = {
                    'text': payload.get('chunk_text', ''),
                    'document_id': payload.get('document_id', ''),
                    'filename': payload.get('filename', ''),
                    'chunk_index': payload.get('chunk_index', 0),
                    'score': r.get('score', 0.0)
                }
                if chunk['text']:
                    chunks.append(chunk)
            
            logger.info(f"[LangGraph RAG] Retrieved {len(chunks)} chunks")
            
            # –ï—Å–ª–∏ –º–∞–ª–æ —á–∞–Ω–∫–æ–≤, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ë–î –Ω–∞–ø—Ä—è–º—É—é
            if len(chunks) < 3 and state.get('document_id'):
                chunks = await self._get_chunks_from_db(state['document_id'])
            
            state['chunks'] = chunks
            state['metadata'] = {
                **state.get('metadata', {}),
                'chunks_retrieved': len(chunks)
            }
            
        except Exception as e:
            logger.error(f"[LangGraph RAG] Retrieval error: {e}", exc_info=True)
            state['chunks'] = []
            state['error'] = f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}"
        
        return state
    
    async def _get_chunks_from_db(self, document_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ë–î"""
        from app.models.document import Document, DocumentChunk
        
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —á–∞–Ω–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã chunks
            result = await self.db.execute(
                select(DocumentChunk)
                .where(DocumentChunk.document_id == UUID(document_id))
                .order_by(DocumentChunk.chunk_index)
                .limit(50)
            )
            db_chunks = result.scalars().all()
            
            if db_chunks:
                return [
                    {
                        'text': chunk.chunk_text,
                        'document_id': str(document_id),
                        'chunk_index': chunk.chunk_index,
                        'score': 1.0
                    }
                    for chunk in db_chunks
                ]
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —á–∞–Ω–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º content –¥–æ–∫—É–º–µ–Ω—Ç–∞
            result = await self.db.execute(
                select(Document).where(Document.id == UUID(document_id))
            )
            document = result.scalar_one_or_none()
            
            if document and document.content:
                # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏
                from app.documents.chunker import DocumentChunker
                chunker = DocumentChunker(
                    chunk_size=self.config.chunk_size,
                    chunk_overlap=self.config.chunk_overlap
                )
                text_chunks = chunker.chunk_text(document.content)
                
                return [
                    {
                        'text': text,
                        'document_id': str(document_id),
                        'filename': document.filename,
                        'chunk_index': i,
                        'score': 1.0
                    }
                    for i, text in enumerate(text_chunks[:50])
                ]
        
        except Exception as e:
            logger.error(f"[LangGraph RAG] DB chunks error: {e}")
        
        return []
    
    async def _build_context_node(self, state: RAGState) -> RAGState:
        """–ù–æ–¥–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —á–∞–Ω–∫–æ–≤"""
        logger.info(f"[LangGraph RAG] Building context from {len(state['chunks'])} chunks")
        
        chunks = state['chunks']
        if not chunks:
            state['context'] = ""
            state['sources'] = []
            return state
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ chunk_index
        chunks_sorted = sorted(
            chunks, 
            key=lambda x: (-x.get('score', 0), x.get('chunk_index', 0))
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        max_context_chars = self.config.max_context_tokens * 3
        
        context_parts = []
        current_length = 0
        sources = set()
        
        for chunk in chunks_sorted:
            text = chunk.get('text', '')
            filename = chunk.get('filename', '–î–æ–∫—É–º–µ–Ω—Ç')
            chunk_index = chunk.get('chunk_index', 0)
            
            if not text:
                continue
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫
            formatted = f"[{filename}, —á–∞—Å—Ç—å {chunk_index + 1}]\n{text}\n"
            
            if current_length + len(formatted) > max_context_chars:
                break
            
            context_parts.append(formatted)
            current_length += len(formatted)
            sources.add(filename)
        
        context = "\n---\n".join(context_parts)
        
        state['context'] = context
        state['sources'] = list(sources)
        state['metadata'] = {
            **state.get('metadata', {}),
            'context_length': len(context),
            'chunks_used': len(context_parts)
        }
        
        logger.info(f"[LangGraph RAG] Context built: {len(context)} chars from {len(context_parts)} chunks")
        
        return state
    
    async def _generate_node(self, state: RAGState) -> RAGState:
        """–ù–æ–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM"""
        logger.info(f"[LangGraph RAG] Generating response for query type: {state['query_type']}")
        
        try:
            from app.llm.openrouter_client import OpenRouterClient
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
            query_type = state['query_type']
            system_prompt = self.config.system_prompts.get(
                query_type, 
                self.config.system_prompts[QueryType.QUESTION]
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
            context = state['context']
            query = state['query']
            
            if query_type == QueryType.SUMMARY:
                user_prompt = f"""–°–æ–∑–¥–∞–π —Ç–æ—á–Ω–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:

–°–û–î–ï–†–ñ–ò–ú–û–ï –î–û–ö–£–ú–ï–ù–¢–ê:
{context}

–†–ï–ó–Æ–ú–ï:"""
            
            elif query_type == QueryType.DESCRIPTION:
                user_prompt = f"""–û–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:

–°–û–î–ï–†–ñ–ò–ú–û–ï –î–û–ö–£–ú–ï–ù–¢–ê:
{context}

–û–ü–ò–°–ê–ù–ò–ï:"""
            
            elif query_type == QueryType.ANALYSIS:
                user_prompt = f"""–ü—Ä–æ–≤–µ–¥–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:

–°–û–î–ï–†–ñ–ò–ú–û–ï –î–û–ö–£–ú–ï–ù–¢–ê:
{context}

–ê–ù–ê–õ–ò–ó:"""
            
            else:  # QueryType.QUESTION
                if context:
                    user_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í:
{context}

–í–û–ü–†–û–°: {query}

–û–¢–í–ï–¢:"""
                else:
                    user_prompt = f"""–í–æ–ø—Ä–æ—Å: {query}

–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.
–°–æ–æ–±—â–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ–± —ç—Ç–æ–º –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω–∏—Ç—å –≤–æ–ø—Ä–æ—Å."""
            
            # –í—ã–∑—ã–≤–∞–µ–º LLM
            llm_client = OpenRouterClient()
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            response = await llm_client.chat_completion_with_usage(
                messages=messages,
                max_tokens=self.config.max_output_tokens,
                temperature=self.config.temperature
            )
            
            state['answer'] = response['content']
            state['confidence'] = 1.0 if context else 0.5
            state['metadata'] = {
                **state.get('metadata', {}),
                'model': response.get('model', 'unknown'),
                'input_tokens': response.get('input_tokens', 0),
                'output_tokens': response.get('output_tokens', 0)
            }
            
            logger.info(f"[LangGraph RAG] Generated answer: {len(state['answer'])} chars")
            
        except Exception as e:
            logger.error(f"[LangGraph RAG] Generation error: {e}", exc_info=True)
            state['answer'] = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
            state['error'] = str(e)
            state['confidence'] = 0.0
        
        return state
    
    async def _format_output_node(self, state: RAGState) -> RAGState:
        """–ù–æ–¥–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        answer = state['answer']
        sources = state['sources']
        
        # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        answer = answer.strip()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if sources and state['query_type'] in [QueryType.QUESTION]:
            sources_text = ", ".join(sources[:3])
            answer += f"\n\nüìÑ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources_text}"
        
        state['answer'] = answer
        
        return state
    
    async def run(
        self,
        query: str,
        query_type: QueryType = QueryType.QUESTION,
        project_id: str = None,
        document_id: str = None
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ RAG workflow
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            query_type: –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞ (–≤–æ–ø—Ä–æ—Å, —Ä–µ–∑—é–º–µ, –æ–ø–∏—Å–∞–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑)
            project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
            document_id: ID –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º, –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not LANGGRAPH_AVAILABLE:
            return await self._fallback_run(query, query_type, project_id, document_id)
        
        initial_state: RAGState = {
            'query': query,
            'query_type': query_type,
            'project_id': project_id or '',
            'document_id': document_id,
            'chunks': [],
            'context': '',
            'answer': '',
            'sources': [],
            'confidence': 0.0,
            'error': None,
            'metadata': {}
        }
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º workflow
            final_state = await self._workflow.ainvoke(initial_state)
            
            return {
                'answer': final_state['answer'],
                'sources': final_state['sources'],
                'confidence': final_state['confidence'],
                'error': final_state.get('error'),
                'metadata': final_state.get('metadata', {})
            }
        
        except Exception as e:
            logger.error(f"[LangGraph RAG] Workflow error: {e}", exc_info=True)
            return await self._fallback_run(query, query_type, project_id, document_id)
    
    async def _fallback_run(
        self,
        query: str,
        query_type: QueryType,
        project_id: str,
        document_id: str
    ) -> Dict[str, Any]:
        """Fallback –º–µ—Ç–æ–¥ –±–µ–∑ LangGraph"""
        logger.info("[LangGraph RAG] Using fallback method (without LangGraph)")
        
        state: RAGState = {
            'query': query,
            'query_type': query_type,
            'project_id': project_id or '',
            'document_id': document_id,
            'chunks': [],
            'context': '',
            'answer': '',
            'sources': [],
            'confidence': 0.0,
            'error': None,
            'metadata': {}
        }
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º –Ω–æ–¥—ã
        state = await self._retrieve_node(state)
        state = await self._build_context_node(state)
        state = await self._generate_node(state)
        state = await self._format_output_node(state)
        
        return {
            'answer': state['answer'],
            'sources': state['sources'],
            'confidence': state['confidence'],
            'error': state.get('error'),
            'metadata': state.get('metadata', {})
        }
    
    # === –£–¥–æ–±–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–∏–ø–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ===
    
    async def answer_question(
        self,
        question: str,
        project_id: str,
        document_id: str = None
    ) -> str:
        """–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        result = await self.run(
            query=question,
            query_type=QueryType.QUESTION,
            project_id=project_id,
            document_id=document_id
        )
        return result['answer']
    
    async def generate_summary(
        self,
        project_id: str,
        document_id: str = None
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        result = await self.run(
            query="–°–æ–∑–¥–∞–π —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            query_type=QueryType.SUMMARY,
            project_id=project_id,
            document_id=document_id
        )
        return result['answer']
    
    async def describe_content(
        self,
        project_id: str,
        document_id: str = None
    ) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        result = await self.run(
            query="–û–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            query_type=QueryType.DESCRIPTION,
            project_id=project_id,
            document_id=document_id
        )
        return result['answer']
    
    async def analyze_document(
        self,
        project_id: str,
        document_id: str = None
    ) -> str:
        """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        result = await self.run(
            query="–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç",
            query_type=QueryType.ANALYSIS,
            project_id=project_id,
            document_id=document_id
        )
        return result['answer']


# === –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é ===
"""
–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ú–û–î–ï–õ–Ø–ú –ò –ü–ê–†–ê–ú–ï–¢–†–ê–ú:

1. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (>100 —Å—Ç—Ä–∞–Ω–∏—Ü):
   - –ú–æ–¥–µ–ª—å: Claude 3.5 Sonnet –∏–ª–∏ GPT-4 Turbo (–±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
   - chunk_size: 2000 —Å–∏–º–≤–æ–ª–æ–≤
   - chunk_overlap: 400 —Å–∏–º–≤–æ–ª–æ–≤
   - top_k_retrieval: 15-20
   - max_context_tokens: 100000

2. –î–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã:
   - –ú–æ–¥–µ–ª—å: GPT-3.5 Turbo –∏–ª–∏ DeepSeek Chat
   - chunk_size: 1000 —Å–∏–º–≤–æ–ª–æ–≤
   - chunk_overlap: 200 —Å–∏–º–≤–æ–ª–æ–≤
   - top_k_retrieval: 5-10
   - max_context_tokens: 15000

3. –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –∏—Å–∫–∞–∂–µ–Ω–∏—è–º–∏:
   - –ú–æ–¥–µ–ª—å: Claude 3.5 Sonnet (–ª—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
   - temperature: 0.1-0.2 (–Ω–∏–∑–∫–∞—è –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)
   - chunk_size: 1500 —Å–∏–º–≤–æ–ª–æ–≤
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å QueryType.SUMMARY

4. –§–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–æ–≤:
   - –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤: "–ù–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å..."
   - –î–ª—è —Ä–µ–∑—é–º–µ: "–°–æ–∑–¥–∞–π —Ç–æ—á–Ω–æ–µ —Ä–µ–∑—é–º–µ, —Å–æ—Ö—Ä–∞–Ω—è—è —Ñ–∞–∫—Ç—ã..."
   - –î–ª—è –æ–ø–∏—Å–∞–Ω–∏—è: "–û–ø–∏—à–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞..."

5. –û–±—ä—ë–º —Ç–µ–∫—Å—Ç–∞:
   - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: 1000-2000 —Å–∏–º–≤–æ–ª–æ–≤
   - –ú–∞–∫—Å–∏–º—É–º —á–∞–Ω–∫–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: 10-20
   - –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: 30-50K —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
"""
