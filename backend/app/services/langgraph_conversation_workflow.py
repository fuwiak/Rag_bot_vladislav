"""
LangGraph Conversation Workflow –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–æ–≤
- –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ
- RAG –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
"""
import logging
from typing import List, Dict, Any, Optional, TypedDict, Literal
from uuid import UUID
from datetime import datetime
from enum import Enum

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc

logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å LangGraph
try:
    from langgraph.graph import StateGraph, END
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    logger.warning("LangGraph –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è conversation workflow")


class ConversationState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ Conversation Workflow"""
    user_id: str
    project_id: str
    message: str
    intent: str  # question, summary, description, general, greeting
    conversation_history: List[Dict[str, str]]
    rag_context: str
    response: str
    use_rag: bool
    sources: List[str]
    metadata: Dict[str, Any]


class ConversationIntent(str, Enum):
    """–ò–Ω—Ç–µ–Ω—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    QUESTION = "question"  # –í–æ–ø—Ä–æ—Å –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
    SUMMARY = "summary"  # –ó–∞–ø—Ä–æ—Å —Ä–µ–∑—é–º–µ
    DESCRIPTION = "description"  # –ó–∞–ø—Ä–æ—Å –æ–ø–∏—Å–∞–Ω–∏—è
    GENERAL = "general"  # –û–±—â–∏–π –≤–æ–ø—Ä–æ—Å (–Ω–µ –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö)
    GREETING = "greeting"  # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ


class LangGraphConversationWorkflow:
    """LangGraph Workflow –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤"""
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self._workflow = None
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ç–µ–Ω—Ç–∞
        self.intent_keywords = {
            ConversationIntent.SUMMARY: [
                "—Ä–µ–∑—é–º–µ", "–∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "–∫—Ä–∞—Ç–∫–æ", "summary", 
                "–æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã", "–∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã", "–≤—ã–∂–∏–º–∫–∞"
            ],
            ConversationIntent.DESCRIPTION: [
                "–æ–ø–∏—à–∏", "–æ–ø–∏—Å–∞–Ω–∏–µ", "describe", "—á—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç", 
                "–æ —á–µ–º –¥–æ–∫—É–º–µ–Ω—Ç", "—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞", "—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"
            ],
            ConversationIntent.GREETING: [
                "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä",
                "hello", "hi", "—Ö–∞–π", "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ"
            ],
            ConversationIntent.GENERAL: [
                "–∫—Ç–æ —Ç—ã", "—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–ø–æ–º–æ—â—å", "help",
                "–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è"
            ]
        }
        
        if LANGGRAPH_AVAILABLE:
            self._build_workflow()
    
    def _build_workflow(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ conversation workflow"""
        workflow = StateGraph(ConversationState)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–¥—ã
        workflow.add_node("classify_intent", self._classify_intent_node)
        workflow.add_node("load_history", self._load_history_node)
        workflow.add_node("retrieve_context", self._retrieve_context_node)
        workflow.add_node("generate_response", self._generate_response_node)
        workflow.add_node("save_message", self._save_message_node)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞—Ñ
        workflow.set_entry_point("classify_intent")
        workflow.add_edge("classify_intent", "load_history")
        
        # –£—Å–ª–æ–≤–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ load_history
        workflow.add_conditional_edges(
            "load_history",
            self._should_use_rag,
            {
                True: "retrieve_context",
                False: "generate_response"
            }
        )
        
        workflow.add_edge("retrieve_context", "generate_response")
        workflow.add_edge("generate_response", "save_message")
        workflow.add_edge("save_message", END)
        
        self._workflow = workflow.compile()
    
    def _should_use_rag(self, state: ConversationState) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ RAG –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        intent = state.get('intent', 'question')
        
        # RAG –Ω–µ –Ω—É–∂–µ–Ω –¥–ª—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –∏ –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –±–æ—Ç–µ
        if intent in [ConversationIntent.GREETING.value, ConversationIntent.GENERAL.value]:
            return False
        
        # –Ø–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG
        if not state.get('use_rag', True):
            return False
        
        return True
    
    async def _classify_intent_node(self, state: ConversationState) -> ConversationState:
        """–ù–æ–¥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        message = state['message'].lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for intent, keywords in self.intent_keywords.items():
            for keyword in keywords:
                if keyword in message:
                    state['intent'] = intent.value
                    logger.info(f"[Conversation] Intent classified: {intent.value}")
                    return state
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –≤–æ–ø—Ä–æ—Å –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        state['intent'] = ConversationIntent.QUESTION.value
        return state
    
    async def _load_history_node(self, state: ConversationState) -> ConversationState:
        """–ù–æ–¥–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        try:
            from app.models.message import Message as MessageModel
            
            user_id = UUID(state['user_id'])
            
            result = await self.db.execute(
                select(MessageModel)
                .where(MessageModel.user_id == user_id)
                .order_by(desc(MessageModel.created_at))
                .limit(10)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
            )
            messages = result.scalars().all()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è LLM
            history = []
            for msg in reversed(messages):  # –û—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
                history.append({
                    "role": msg.role,
                    "content": msg.content
                })
            
            state['conversation_history'] = history
            logger.info(f"[Conversation] Loaded {len(history)} messages from history")
            
        except Exception as e:
            logger.warning(f"[Conversation] Failed to load history: {e}")
            state['conversation_history'] = []
        
        return state
    
    async def _retrieve_context_node(self, state: ConversationState) -> ConversationState:
        """–ù–æ–¥–∞ –ø–æ–ª—É—á–µ–Ω–∏—è RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            from app.services.langgraph_rag_workflow import (
                LangGraphRAGWorkflow, 
                QueryType
            )
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è RAG
            intent = state['intent']
            if intent == ConversationIntent.SUMMARY.value:
                query_type = QueryType.SUMMARY
            elif intent == ConversationIntent.DESCRIPTION.value:
                query_type = QueryType.DESCRIPTION
            else:
                query_type = QueryType.QUESTION
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º RAG workflow
            rag_workflow = LangGraphRAGWorkflow(self.db)
            result = await rag_workflow.run(
                query=state['message'],
                query_type=query_type,
                project_id=state['project_id']
            )
            
            state['rag_context'] = result.get('answer', '')
            state['sources'] = result.get('sources', [])
            state['metadata'] = {
                **state.get('metadata', {}),
                'rag_metadata': result.get('metadata', {})
            }
            
            logger.info(f"[Conversation] RAG context retrieved: {len(state['rag_context'])} chars")
            
        except Exception as e:
            logger.error(f"[Conversation] RAG retrieval error: {e}", exc_info=True)
            state['rag_context'] = ''
            state['sources'] = []
        
        return state
    
    async def _generate_response_node(self, state: ConversationState) -> ConversationState:
        """–ù–æ–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
        intent = state['intent']
        
        # –î–ª—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π - —à–∞–±–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        if intent == ConversationIntent.GREETING.value:
            state['response'] = (
                "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏.\n\n"
                "–Ø –º–æ–≥—É:\n"
                "üìÑ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º\n"
                "üìã –°–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (/summary)\n"
                "üìù –û–ø–∏—Å—ã–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (/describe)\n"
                "üí° –ü—Ä–µ–¥–ª–∞–≥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã (/suggest_questions)\n\n"
                "–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –Ω–∞–π–¥—É –æ—Ç–≤–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö!"
            )
            return state
        
        # –î–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –±–æ—Ç–µ
        if intent == ConversationIntent.GENERAL.value:
            state['response'] = (
                "ü§ñ –Ø RAG-–±–æ—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏.\n\n"
                "–ú–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n"
                "‚Ä¢ –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö\n"
                "‚Ä¢ –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
                "‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–π\n"
                "‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ PDF, Word, Excel\n\n"
                "–ö–æ–º–∞–Ω–¥—ã:\n"
                "/documents - —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
                "/summary - —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n"
                "/describe - –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è\n"
                "/suggest_questions - –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã"
            )
            return state
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é
        if state.get('rag_context'):
            state['response'] = state['rag_context']
            return state
        
        # Fallback - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ LLM
        try:
            from app.llm.openrouter_client import OpenRouterClient
            
            llm_client = OpenRouterClient()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏—Å—Ç–æ—Ä–∏–µ–π
            messages = [
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
                        "–ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."
                    )
                }
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
            for msg in state.get('conversation_history', [])[-5:]:
                messages.append(msg)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            messages.append({
                "role": "user",
                "content": state['message']
            })
            
            response = await llm_client.chat_completion(
                messages=messages,
                max_tokens=2048,
                temperature=0.7
            )
            
            state['response'] = response
            
        except Exception as e:
            logger.error(f"[Conversation] Generation error: {e}", exc_info=True)
            state['response'] = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        
        return state
    
    async def _save_message_node(self, state: ConversationState) -> ConversationState:
        """–ù–æ–¥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏—é"""
        try:
            from app.models.message import Message as MessageModel
            
            user_id = UUID(state['user_id'])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_msg = MessageModel(
                user_id=user_id,
                content=state['message'],
                role="user",
                created_at=datetime.utcnow()
            )
            self.db.add(user_msg)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
            bot_msg = MessageModel(
                user_id=user_id,
                content=state['response'],
                role="assistant",
                created_at=datetime.utcnow()
            )
            self.db.add(bot_msg)
            
            await self.db.commit()
            logger.info(f"[Conversation] Messages saved for user {user_id}")
            
        except Exception as e:
            logger.warning(f"[Conversation] Failed to save messages: {e}")
            await self.db.rollback()
        
        return state
    
    async def run(
        self,
        user_id: str,
        project_id: str,
        message: str,
        use_rag: bool = True
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ conversation workflow
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            use_rag: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        initial_state: ConversationState = {
            'user_id': user_id,
            'project_id': project_id,
            'message': message,
            'intent': '',
            'conversation_history': [],
            'rag_context': '',
            'response': '',
            'use_rag': use_rag,
            'sources': [],
            'metadata': {}
        }
        
        try:
            if LANGGRAPH_AVAILABLE and self._workflow:
                final_state = await self._workflow.ainvoke(initial_state)
            else:
                # Fallback –±–µ–∑ LangGraph
                final_state = await self._fallback_run(initial_state)
            
            return {
                'response': final_state['response'],
                'intent': final_state['intent'],
                'sources': final_state['sources'],
                'metadata': final_state.get('metadata', {})
            }
        
        except Exception as e:
            logger.error(f"[Conversation] Workflow error: {e}", exc_info=True)
            return {
                'response': "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                'intent': 'error',
                'sources': [],
                'metadata': {'error': str(e)}
            }
    
    async def _fallback_run(self, state: ConversationState) -> ConversationState:
        """Fallback –º–µ—Ç–æ–¥ –±–µ–∑ LangGraph"""
        state = await self._classify_intent_node(state)
        state = await self._load_history_node(state)
        
        if self._should_use_rag(state):
            state = await self._retrieve_context_node(state)
        
        state = await self._generate_response_node(state)
        state = await self._save_message_node(state)
        
        return state


class ConversationHistoryIndexer:
    """–ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def index_conversation(
        self,
        user_id: str,
        messages: List[Dict[str, str]]
    ) -> bool:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        try:
            from app.services.embedding_service import EmbeddingService
            from app.vector_db.vector_store import VectorStore
            
            embedding_service = EmbeddingService()
            vector_store = VectorStore()
            
            collection_name = f"conversations_{user_id}"
            
            for i, msg in enumerate(messages):
                content = msg.get('content', '')
                role = msg.get('role', 'user')
                
                if not content or len(content) < 10:
                    continue
                
                # –°–æ–∑–¥–∞–µ–º embedding
                embedding = await embedding_service.create_embedding(content)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
                await vector_store.store_vector(
                    collection_name=collection_name,
                    vector=embedding,
                    payload={
                        'user_id': user_id,
                        'role': role,
                        'content': content,
                        'message_index': i,
                        'indexed_at': datetime.utcnow().isoformat()
                    }
                )
            
            logger.info(f"[ConversationIndexer] Indexed {len(messages)} messages for user {user_id}")
            return True
            
        except Exception as e:
            logger.error(f"[ConversationIndexer] Indexing error: {e}", exc_info=True)
            return False
    
    async def search_history(
        self,
        user_id: str,
        query: str,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        try:
            from app.services.embedding_service import EmbeddingService
            from app.vector_db.vector_store import VectorStore
            
            embedding_service = EmbeddingService()
            vector_store = VectorStore()
            
            # –°–æ–∑–¥–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await embedding_service.create_embedding(query)
            
            collection_name = f"conversations_{user_id}"
            
            # –ü–æ–∏—Å–∫
            results = await vector_store.search_similar(
                collection_name=collection_name,
                query_vector=query_embedding,
                limit=limit,
                score_threshold=0.5
            )
            
            return [
                {
                    'content': r.get('payload', {}).get('content', ''),
                    'role': r.get('payload', {}).get('role', ''),
                    'score': r.get('score', 0.0)
                }
                for r in results
            ]
            
        except Exception as e:
            logger.warning(f"[ConversationIndexer] Search error: {e}")
            return []
