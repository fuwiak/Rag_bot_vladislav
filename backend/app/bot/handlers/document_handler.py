"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Telegram –±–æ—Ç
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ó–∞–≥—Ä—É–∑–∫—É PDF, Excel, Word, TXT —Ñ–∞–π–ª–æ–≤
- –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant –¥–ª—è RAG
"""
from aiogram import Dispatcher, F
from aiogram.types import Message, Document as TelegramDocument
from aiogram.enums import ChatAction
from aiogram.fsm.context import FSMContext
from uuid import UUID
import logging
import os
import tempfile
from pathlib import Path
import uuid as uuid_module

from app.core.database import AsyncSessionLocal
from app.bot.handlers.auth_handler import AuthStates
from app.models.document import Document
from app.tasks.document_tasks import process_document_task, process_large_document_with_langgraph
from app.services.document_agent_adapter import DocumentAgentAdapter

logger = logging.getLogger(__name__)


async def extract_text_from_file(file_path: str, file_extension: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤"""
    try:
        if file_extension == 'pdf':
            # PDF
            from PyPDF2 import PdfReader
            reader = PdfReader(file_path)
            text = ""
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n\n"
            return text
        
        elif file_extension == 'docx':
            # Word –¥–æ–∫—É–º–µ–Ω—Ç—ã
            try:
                import docx
                doc = docx.Document(file_path)
                text = ""
                for para in doc.paragraphs:
                    text += para.text + "\n"
                return text
            except ImportError:
                logger.warning("python-docx not installed, trying alternative method")
                return ""
        
        elif file_extension in ['xlsx', 'xls']:
            # Excel —Ñ–∞–π–ª—ã
            try:
                import pandas as pd
                df = pd.read_excel(file_path)
                return df.to_string()
            except ImportError:
                logger.warning("pandas/openpyxl not installed")
                return ""
        
        elif file_extension == 'txt' or file_extension == 'md':
            # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        else:
            logger.warning(f"Unsupported file format: {file_extension}")
            return ""
            
    except Exception as e:
        logger.error(f"Error extracting text from {file_extension} file: {e}")
        return ""


async def index_document_to_qdrant(
    text_content: str,
    file_name: str,
    user_id: str,
    username: str,
    project_id: str = None
) -> dict:
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Qdrant (–∫–æ–ª–ª–µ–∫—Ü–∏—è 'data')
    
    Args:
        text_content: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
        file_name: –ò–º—è —Ñ–∞–π–ª–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è Telegram
        username: Username –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        {"success": bool, "chunks_count": int, "error": str}
    """
    try:
        from app.services.rag.qdrant_helper import index_document_chunks_to_qdrant
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_id = str(uuid_module.uuid4())
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
        try:
            from langchain_text_splitters import RecursiveCharacterTextSplitter
        except ImportError:
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Å–ø–ª–∏—Ç—Ç–µ—Ä
            class RecursiveCharacterTextSplitter:
                def __init__(self, chunk_size=500, chunk_overlap=50, separators=None):
                    self.chunk_size = chunk_size
                    self.chunk_overlap = chunk_overlap
                    self.separators = separators or ["\n\n", "\n", ". ", " ", ""]
                
                def split_text(self, text):
                    chunks = []
                    current_chunk = ""
                    
                    for sep in self.separators:
                        if sep in text:
                            parts = text.split(sep)
                            for part in parts:
                                if len(current_chunk) + len(part) + len(sep) <= self.chunk_size:
                                    current_chunk += part + sep
                                else:
                                    if current_chunk:
                                        chunks.append(current_chunk.strip())
                                    current_chunk = part + sep
                            break
                    
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç —á–∞–Ω–∫–æ–≤, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
                    if not chunks:
                        for i in range(0, len(text), self.chunk_size - self.chunk_overlap):
                            chunk = text[i:i + self.chunk_size]
                            if chunk.strip():
                                chunks.append(chunk.strip())
                    
                    return chunks
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        chunks = text_splitter.split_text(text_content)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏
        chunks = [chunk for chunk in chunks if len(chunk.strip()) >= 10]
        
        logger.info(f"üìÑ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_name}")
        
        if not chunks:
            return {
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            }
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –≤ Qdrant
        result = await index_document_chunks_to_qdrant(
            chunks=chunks,
            file_name=file_name,
            doc_id=doc_id,
            user_id=user_id,
            username=username,
            project_id=project_id
        )
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Qdrant: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }


async def handle_document(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (PDF, Excel)"""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    current_state = await state.get_state()
    if current_state != AuthStates.authorized:
        await message.answer("‚ùå –°–Ω–∞—á–∞–ª–∞ –∞–≤—Ç–æ—Ä–∏–∑—É–π—Ç–µ—Å—å —á–µ—Ä–µ–∑ /start")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º project_id –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    data = await state.get_data()
    project_id_str = data.get("project_id")
    
    if not project_id_str:
        await message.answer("‚ùå –û—à–∏–±–∫–∞: –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start")
        return
    
    try:
        project_id = UUID(project_id_str)
    except ValueError:
        await message.answer("‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π ID –ø—Ä–æ–µ–∫—Ç–∞")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç
    if not message.document:
        await message.answer("‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª (PDF –∏–ª–∏ Excel)")
        return
    
    doc = message.document
    file_name = doc.file_name or "document"
    file_size = doc.file_size or 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 50MB)
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    if file_size > MAX_FILE_SIZE:
        await message.answer(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE / 1024 / 1024:.0f}MB")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
    file_ext = Path(file_name).suffix.lower()
    if file_ext not in ['.pdf', '.xlsx', '.xls', '.docx', '.txt']:
        await message.answer("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã: PDF, Excel (.xlsx, .xls), Word (.docx), TXT")
        return
    
    file_type = file_ext.lstrip('.')
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–µ—á–∞—Ç–∏
    try:
        await message.bot.send_chat_action(message.chat.id, ChatAction.TYPING)
    except Exception as e:
        logger.warning(f"Failed to send typing indicator: {e}")
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    processing_msg = await message.answer(f"üì• –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª: {file_name}...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        bot = message.bot
        file_info = await bot.get_file(doc.file_id)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_dir = Path(tempfile.gettempdir())
        temp_file = temp_dir / f"telegram_upload_{doc.file_id}_{file_name}"
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        await bot.download_file(file_info.file_path, destination=temp_file)
        
        logger.info(f"[TELEGRAM UPLOAD] File downloaded: {temp_file}, size: {file_size} bytes")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        with open(temp_file, 'rb') as f:
            file_content = f.read()
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            os.unlink(temp_file)
        except Exception as e:
            logger.warning(f"Failed to delete temp file: {e}")
        
        async with AsyncSessionLocal() as db:
            # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –ë–î
            document = Document(
                project_id=project_id,
                filename=file_name,
                content="–û–±—Ä–∞–±–æ—Ç–∫–∞...",  # –í—Ä–µ–º–µ–Ω–Ω—ã–π placeholder
                file_type=file_type
            )
            db.add(document)
            await db.commit()
            await db.refresh(document)
            
            logger.info(f"[TELEGRAM UPLOAD] Document created in DB: {document.id}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            media_dir = Path("media") / "documents" / str(project_id)
            media_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            original_file_path = media_dir / f"{document.id}_{file_name}"
            with open(original_file_path, 'wb') as f:
                f.write(file_content)
            logger.info(f"[TELEGRAM UPLOAD] Original file saved: {original_file_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è Celery –∑–∞–¥–∞—á–∏
            temp_path = temp_dir / f"celery_doc_{document.id}_{file_name}"
            with open(temp_path, 'wb') as f:
                f.write(file_content)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –±–æ–ª—å—à–æ–π –ª–∏ —ç—Ç–æ PDF –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±—ã—Å—Ç—Ä–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            is_large_pdf = (
                file_type == "pdf" and 
                file_size > 5 * 1024 * 1024  # –ë–æ–ª—å—à–µ 5MB
            )
            
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è PDF
            if is_large_pdf:
                try:
                    adapter = DocumentAgentAdapter()
                    preview_text = await adapter._quick_pdf_preview(file_content)
                    estimated_pages = len(preview_text) // 3000 if preview_text else 0
                    
                    if estimated_pages > 100:
                        is_large_pdf = True
                        logger.info(f"[TELEGRAM UPLOAD] –ë–æ–ª—å—à–æ–π PDF –æ–±–Ω–∞—Ä—É–∂–µ–Ω: ~{estimated_pages} —Å—Ç—Ä–∞–Ω–∏—Ü, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é")
                    else:
                        is_large_pdf = False
                except Exception as e:
                    logger.warning(f"[TELEGRAM UPLOAD] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä PDF: {e}")
                    is_large_pdf = False
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if is_large_pdf:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –±–æ–ª—å—à–∏—Ö PDF
                logger.info(f"[TELEGRAM UPLOAD] –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–ª—è –±–æ–ª—å—à–æ–≥–æ PDF")
                task_result = process_large_document_with_langgraph.delay(
                    str(document.id),
                    str(project_id),
                    str(temp_path),
                    file_name,
                    file_type
                )
            else:
                # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                task_result = process_document_task.delay(
                    str(document.id),
                    str(project_id),
                    str(temp_path),
                    file_name,
                    file_type
                )
            
            logger.info(f"[TELEGRAM UPLOAD] Celery task created: {task_result.id} for document {document.id}, is_large_pdf: {is_large_pdf}")
            
            # –¢–∞–∫–∂–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ Qdrant –¥–ª—è RAG
            try:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º typing indicator –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                try:
                    await message.bot.send_chat_action(message.chat.id, ChatAction.TYPING)
                except:
                    pass
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è Qdrant
                text_content = await extract_text_from_file(str(temp_path), file_type)
                
                if text_content and text_content.strip():
                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    telegram_user_id = str(message.from_user.id)
                    telegram_username = message.from_user.username or "unknown"
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º typing indicator –ø–µ—Ä–µ–¥ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π
                    try:
                        await message.bot.send_chat_action(message.chat.id, ChatAction.TYPING)
                    except:
                        pass
                    
                    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤ Qdrant
                    qdrant_result = await index_document_to_qdrant(
                        text_content=text_content,
                        file_name=file_name,
                        user_id=telegram_user_id,
                        username=telegram_username,
                        project_id=str(project_id)
                    )
                    
                    if qdrant_result.get("success"):
                        chunks_count = qdrant_result.get("chunks_count", 0)
                        logger.info(f"[TELEGRAM UPLOAD] ‚úÖ Document indexed in Qdrant: {chunks_count} chunks")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º typing –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –æ—Ç–≤–µ—Ç–∞
                        try:
                            await message.bot.send_chat_action(message.chat.id, ChatAction.TYPING)
                        except:
                            pass
                        
                        status_text = (
                            f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω!\n\n"
                            f"üìÑ –ù–∞–∑–≤–∞–Ω–∏–µ: {file_name}\n"
                            f"üìä –¢–∏–ø: {file_type.upper()}\n"
                            f"üìè –†–∞–∑–º–µ—Ä: {file_size / 1024 / 1024:.2f} MB\n"
                            f"üîç –ß–∞–Ω–∫–æ–≤ –≤ RAG: {chunks_count}\n"
                        )
                        if is_large_pdf:
                            status_text += f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–æ–≥–æ PDF\n"
                        status_text += (
                            f"\n‚è≥ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ.\n"
                            f"üìö –î–æ–∫—É–º–µ–Ω—Ç —É–∂–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞!\n"
                            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /documents –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                        )
                        await processing_msg.edit_text(status_text)
                    else:
                        error_msg = qdrant_result.get("error", "Unknown error")
                        logger.warning(f"[TELEGRAM UPLOAD] ‚ö†Ô∏è Qdrant indexing failed: {error_msg}")
                        
                        await processing_msg.edit_text(
                            f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω!\n\n"
                            f"üìÑ –ù–∞–∑–≤–∞–Ω–∏–µ: {file_name}\n"
                            f"üìä –¢–∏–ø: {file_type.upper()}\n"
                            f"üìè –†–∞–∑–º–µ—Ä: {file_size / 1024:.1f} KB\n\n"
                            f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç–∞.\n"
                            f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ RAG –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–∑–∂–µ.\n"
                            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /documents –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                        )
                else:
                    logger.warning(f"[TELEGRAM UPLOAD] ‚ö†Ô∏è No text extracted from document for Qdrant")
                    await processing_msg.edit_text(
                        f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω!\n\n"
                        f"üìÑ –ù–∞–∑–≤–∞–Ω–∏–µ: {file_name}\n"
                        f"üìä –¢–∏–ø: {file_type.upper()}\n"
                        f"üìè –†–∞–∑–º–µ—Ä: {file_size / 1024:.1f} KB\n\n"
                        f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç–∞. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.\n"
                        f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /documents –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                    )
                    
            except Exception as qdrant_error:
                logger.error(f"[TELEGRAM UPLOAD] ‚ùå Qdrant indexing error: {qdrant_error}")
                import traceback
                logger.error(traceback.format_exc())
                
                # –í—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É (Celery –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∑–∂–µ)
                await processing_msg.edit_text(
                    f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω!\n\n"
                    f"üìÑ –ù–∞–∑–≤–∞–Ω–∏–µ: {file_name}\n"
                    f"üìä –¢–∏–ø: {file_type.upper()}\n"
                    f"üìè –†–∞–∑–º–µ—Ä: {file_size / 1024:.1f} KB\n\n"
                    f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç–∞. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /documents –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                )
    
    except Exception as e:
        logger.error(f"[TELEGRAM UPLOAD] Error uploading document: {e}", exc_info=True)
        await processing_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
        )


def register_document_handlers(dp: Dispatcher, project_id: str):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    import logging
    logger = logging.getLogger(__name__)
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)
    dp.message.register(handle_document, AuthStates.authorized, F.document)
    logger.info(f"[REGISTER HANDLERS] Document handlers registered for project {project_id}")

